{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: runs/train\\testing3\\results.csv\n",
      "Columns in runs/train\\testing3\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\testing4\\results.csv\n",
      "Columns in runs/train\\testing4\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train\\results.csv\n",
      "Columns in runs/train\\train\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train10\\results.csv\n",
      "Columns in runs/train\\train10\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train11\\results.csv\n",
      "Columns in runs/train\\train11\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train12\\results.csv\n",
      "Columns in runs/train\\train12\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train13\\results.csv\n",
      "Columns in runs/train\\train13\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train14\\results.csv\n",
      "Columns in runs/train\\train14\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train2\\results.csv\n",
      "Columns in runs/train\\train2\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train3\\results.csv\n",
      "Columns in runs/train\\train3\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train4\\results.csv\n",
      "Columns in runs/train\\train4\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train5\\results.csv\n",
      "Columns in runs/train\\train5\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train6\\results.csv\n",
      "Columns in runs/train\\train6\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train7\\results.csv\n",
      "Columns in runs/train\\train7\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train8\\results.csv\n",
      "Columns in runs/train\\train8\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Processing: runs/train\\train9\\results.csv\n",
      "Columns in runs/train\\train9\\results.csv: ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n",
      "Metrics saved to aggregated_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_metrics(base_dir, epochs, output_file):\n",
    "    # Metrics to extract\n",
    "    metrics = [\n",
    "        \"epoch\",\n",
    "        \"train/box_loss\",\n",
    "        \"train/cls_loss\",\n",
    "        \"train/dfl_loss\",\n",
    "        \"metrics/precision(B)\",\n",
    "        \"metrics/recall(B)\",\n",
    "        \"metrics/mAP50-95(B)\",\n",
    "    ]\n",
    "\n",
    "    # List to store results from all runs\n",
    "    aggregated_results = []\n",
    "\n",
    "    # Loop through each run directory\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file == \"results.csv\":\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing: {file_path}\")\n",
    "\n",
    "                try:\n",
    "                    # Load the CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Clean column names to ensure consistency\n",
    "                    df.columns = df.columns.str.strip()\n",
    "\n",
    "                    # Debug: Print column names\n",
    "                    print(f\"Columns in {file_path}: {df.columns.tolist()}\")\n",
    "\n",
    "                    # Check if required columns exist\n",
    "                    missing_columns = [col for col in metrics if col not in df.columns]\n",
    "                    if missing_columns:\n",
    "                        print(f\"Missing columns in {file_path}: {missing_columns}\")\n",
    "                        continue\n",
    "\n",
    "                    # Filter the rows for the specified epochs\n",
    "                    df_filtered = df[df[\"epoch\"].isin(epochs)]\n",
    "\n",
    "                    # Extract only the specified metrics\n",
    "                    df_filtered = df_filtered[metrics]\n",
    "\n",
    "                    # Add run identifier\n",
    "                    run_name = os.path.basename(os.path.dirname(file_path))\n",
    "                    df_filtered.insert(0, \"run\", run_name)\n",
    "\n",
    "                    # Append to aggregated results\n",
    "                    aggregated_results.append(df_filtered)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    # Concatenate all results into a single DataFrame\n",
    "    if aggregated_results:\n",
    "        final_df = pd.concat(aggregated_results, ignore_index=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        print(f\"Metrics saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "base_directory = \"runs/train\"\n",
    "epochs_to_extract = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "output_csv = \"aggregated_metrics.csv\"\n",
    "\n",
    "# Run the function\n",
    "extract_metrics(base_directory, epochs_to_extract, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
